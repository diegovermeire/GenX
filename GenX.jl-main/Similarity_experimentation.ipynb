{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Normalize the data excluding the 'Time_Index' column\n",
    "scaler = StandardScaler()\n",
    "df_tot_normalized = scaler.fit_transform(df_tot.drop(columns=['Time_Index']))\n",
    "df_tot_normalized_df = pd.DataFrame(df_tot_normalized, columns=df_tot.columns.drop('Time_Index'))\n",
    "df_tot_norm_w_tindex = pd.concat([df_tot[['Time_Index']].reset_index(drop=True), df_tot_normalized_df], axis=1)\n",
    "\n",
    "# Initialize dictionary to store DataFrames for each epsilon\n",
    "consecutive_hours_dfs = {}\n",
    "\n",
    "# Epsilon values to test\n",
    "epsilon_values = [0.8, 0.2]\n",
    "\n",
    "for eps in epsilon_values:\n",
    "    # Apply DBSCAN\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=2)\n",
    "    labels = dbscan.fit_predict(df_tot_normalized)\n",
    "    \n",
    "    # Create a DataFrame to store clustering results for this epsilon\n",
    "    df_epsilon = df_tot.copy()\n",
    "    df_epsilon['Cluster'] = labels\n",
    "    \n",
    "    # Identify clusters with at least one consecutive pair of hours\n",
    "    valid_clusters = []\n",
    "    consecutive_rows = []  # Store rows with consecutive hours for each epsilon\n",
    "    for label in set(labels):\n",
    "        if label != -1:  # Exclude noise points (-1)\n",
    "            cluster_group = df_epsilon[df_epsilon['Cluster'] == label]\n",
    "            consecutive_indices = []\n",
    "\n",
    "            # Check for consecutive hours\n",
    "            for i in range(len(cluster_group) - 1):\n",
    "                if cluster_group['Time_Index'].iloc[i] + 1 == cluster_group['Time_Index'].iloc[i + 1]:\n",
    "                    consecutive_indices.append(cluster_group.index[i])  # Add current index\n",
    "                    # Add the last consecutive index in the pair\n",
    "                    if i == len(cluster_group) - 2:\n",
    "                        consecutive_indices.append(cluster_group.index[i + 1])\n",
    "\n",
    "            # If there are consecutive indices, save the cluster as valid\n",
    "            if consecutive_indices:\n",
    "                valid_clusters.append(label)\n",
    "                consecutive_rows.extend(consecutive_indices)\n",
    "\n",
    "    # Filter the DataFrame to include only rows with consecutive hours and valid clusters\n",
    "    df_consecutive = df_epsilon.loc[consecutive_rows].copy()\n",
    "    \n",
    "    # Store the DataFrame in the dictionary with epsilon as key\n",
    "    consecutive_hours_dfs[eps] = df_consecutive\n",
    "\n",
    "# Display the DataFrames for epsilon 0.8 and 0.2\n",
    "print(\"Consecutive hours DataFrame for epsilon = 0.8:\")\n",
    "print(consecutive_hours_dfs[0.8])\n",
    "\n",
    "print(\"\\nConsecutive hours DataFrame for epsilon = 0.2:\")\n",
    "print(consecutive_hours_dfs[0.2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the frequency over cluster size and variance for clusters that contain consecutive hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Normalize the data excluding the 'Time_Index' column\n",
    "scaler = StandardScaler()\n",
    "df_tot_normalized = scaler.fit_transform(df_tot.drop(columns=['Time_Index']))\n",
    "df_tot_normalized_df = pd.DataFrame(df_tot_normalized, columns=df_tot.columns.drop('Time_Index'))\n",
    "df_tot_norm_w_tindex = pd.concat([df_tot[['Time_Index']].reset_index(drop=True), df_tot_normalized_df], axis=1)\n",
    "\n",
    "# Initialize list to store results and DataFrames for each epsilon\n",
    "epsilon_results = []\n",
    "consecutive_hours_dfs = {}  # To store DataFrames for consecutive hours for each epsilon\n",
    "\n",
    "# Epsilon values to test\n",
    "epsilon_values = [0.8, 0.2]\n",
    "\n",
    "for eps in epsilon_values:\n",
    "    # Apply DBSCAN\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=2)\n",
    "    labels = dbscan.fit_predict(df_tot_normalized)\n",
    "    \n",
    "    # Create a DataFrame to store clustering results for this epsilon\n",
    "    df_epsilon = df_tot.copy()\n",
    "    df_epsilon['Cluster'] = labels\n",
    "    \n",
    "    # Identify clusters with at least one consecutive pair of hours\n",
    "    valid_clusters = []\n",
    "    consecutive_rows = []  # Store rows with consecutive hours for each epsilon\n",
    "    for label in set(labels):\n",
    "        if label != -1:  # Exclude noise points (-1)\n",
    "            cluster_group = df_epsilon[df_epsilon['Cluster'] == label]\n",
    "            consecutive_indices = []\n",
    "\n",
    "            # Check for consecutive hours\n",
    "            for i in range(len(cluster_group) - 1):\n",
    "                if cluster_group['Time_Index'].iloc[i] + 1 == cluster_group['Time_Index'].iloc[i + 1]:\n",
    "                    consecutive_indices.append(cluster_group.index[i])  # Add current index\n",
    "                    # Add the last consecutive index in the pair\n",
    "                    if i == len(cluster_group) - 2:\n",
    "                        consecutive_indices.append(cluster_group.index[i + 1])\n",
    "\n",
    "            # If there are consecutive indices, save the cluster as valid\n",
    "            if consecutive_indices:\n",
    "                valid_clusters.append(label)\n",
    "                consecutive_rows.extend(consecutive_indices)\n",
    "\n",
    "    # Filter the DataFrame to include only rows with consecutive hours and valid clusters\n",
    "    df_consecutive = df_epsilon.loc[consecutive_rows].copy()\n",
    "    \n",
    "    # Store the DataFrame in the dictionary with epsilon as key\n",
    "    consecutive_hours_dfs[eps] = df_consecutive\n",
    "\n",
    "    # Filter for plotting\n",
    "    filtered_df = df_epsilon[df_epsilon['Cluster'].isin(valid_clusters)]\n",
    "\n",
    "    # Collect cluster sizes and variances for valid clusters\n",
    "    cluster_sizes = filtered_df['Cluster'].value_counts()\n",
    "    cluster_variances = filtered_df.groupby('Cluster').var().mean(axis=1)\n",
    "\n",
    "    # Plot the results\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig.suptitle(f'DBSCAN Analysis for epsilon = {eps} (Clusters with Consecutive Hours)', fontsize=16)\n",
    "\n",
    "    # Plot Cluster Size Frequency\n",
    "    sns.histplot(cluster_sizes, kde=False, bins=35, ax=axes[0], log_scale=(True, False))\n",
    "    axes[0].set_title('Cluster Size Frequency (Log Scale)')\n",
    "    axes[0].set_xlabel('Cluster Size')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].grid(True)\n",
    "    total_clusters = len(cluster_sizes)\n",
    "    axes[0].text(\n",
    "        0.95, 0.95,\n",
    "        f'Total Clusters with Consecutive Hours: {total_clusters}',\n",
    "        transform=axes[0].transAxes,\n",
    "        fontsize=10,\n",
    "        color='black',\n",
    "        ha='right',\n",
    "        va='top',\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"gray\", facecolor=\"white\", alpha=0.8)\n",
    "    )\n",
    "\n",
    "    # Plot Cluster Variance Frequency\n",
    "    sns.histplot(cluster_variances, kde=False, bins=35, ax=axes[1], log_scale=(True, False))\n",
    "    axes[1].set_title('Avg. Variance within Clusters (Log Scale)')\n",
    "    axes[1].set_xlabel('Cluster Avg. Variance')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    # Display the figure\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "    \n",
    "    # Store the results for each epsilon\n",
    "    result = {\n",
    "        'Epsilon': eps,\n",
    "        'Num_Clusters_With_Consecutive_Hours': len(cluster_sizes),\n",
    "        'Mean_Cluster_Variance': cluster_variances.mean()\n",
    "    }\n",
    "    epsilon_results.append(result)\n",
    "\n",
    "# Create a DataFrame to display the summary results for each epsilon\n",
    "epsilon_summary_df = pd.DataFrame(epsilon_results)\n",
    "print(epsilon_summary_df)\n",
    "\n",
    "# Display each DataFrame for consecutive hours by epsilon\n",
    "for eps, df_consecutive in consecutive_hours_dfs.items():\n",
    "    print(f\"\\nConsecutive hours DataFrame for epsilon = {eps}:\")\n",
    "    print(df_consecutive)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
